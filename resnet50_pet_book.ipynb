{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Project Title: Fine-Tuning ResNet50 on Oxford-IIIT Pet Dataset**  \n",
    "**Description:**  \n",
    "This project demonstrates the fine-tuning of a pre-trained ResNet50 model on the Oxford-IIIT Pet dataset. The dataset contains 37 classes of cats and dogs, and the goal is to classify images accurately into these categories. Using transfer learning, the ResNet50 model, pre-trained on ImageNet, was adapted to this specific task by modifying the final layers and optimizing the model for the pet classification problem. The notebook covers data preprocessing, model training, evaluation, and predictions on sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading module from GitHub by mrdbourke\n",
    "use module in going_modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Checking if required files and folders already exist.\n",
      "[INFO] Downloading module from GitHub by mrdbourke.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-deep-learning'...\n",
      "Updating files:  54% (135/248)\n",
      "Updating files:  55% (137/248)\n",
      "Updating files:  56% (139/248)\n",
      "Updating files:  57% (142/248)\n",
      "Updating files:  58% (144/248)\n",
      "Updating files:  59% (147/248)\n",
      "Updating files:  60% (149/248)\n",
      "Updating files:  61% (152/248)\n",
      "Updating files:  62% (154/248)\n",
      "Updating files:  63% (157/248)\n",
      "Updating files:  64% (159/248)\n",
      "Updating files:  65% (162/248)\n",
      "Updating files:  66% (164/248)\n",
      "Updating files:  67% (167/248)\n",
      "Updating files:  68% (169/248)\n",
      "Updating files:  69% (172/248)\n",
      "Updating files:  70% (174/248)\n",
      "Updating files:  71% (177/248)\n",
      "Updating files:  72% (179/248)\n",
      "Updating files:  73% (182/248)\n",
      "Updating files:  74% (184/248)\n",
      "Updating files:  75% (186/248)\n",
      "Updating files:  76% (189/248)\n",
      "Updating files:  77% (191/248)\n",
      "Updating files:  78% (194/248)\n",
      "Updating files:  79% (196/248)\n",
      "Updating files:  80% (199/248)\n",
      "Updating files:  81% (201/248)\n",
      "Updating files:  82% (204/248)\n",
      "Updating files:  83% (206/248)\n",
      "Updating files:  84% (209/248)\n",
      "Updating files:  85% (211/248)\n",
      "Updating files:  86% (214/248)\n",
      "Updating files:  87% (216/248)\n",
      "Updating files:  88% (219/248)\n",
      "Updating files:  89% (221/248)\n",
      "Updating files:  90% (224/248)\n",
      "Updating files:  91% (226/248)\n",
      "Updating files:  92% (229/248)\n",
      "Updating files:  93% (231/248)\n",
      "Updating files:  94% (234/248)\n",
      "Updating files:  95% (236/248)\n",
      "Updating files:  96% (239/248)\n",
      "Updating files:  97% (241/248)\n",
      "Updating files:  98% (244/248)\n",
      "Updating files:  99% (246/248)\n",
      "Updating files: 100% (248/248)\n",
      "Updating files: 100% (248/248), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 dir(s) moved.\n",
      "        1 file(s) moved.\n",
      "[INFO] Download and setup completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"[INFO] Checking if required files and folders already exist.\")\n",
    "\n",
    "# ตรวจสอบว่ามีโฟลเดอร์ 'going_modular' และไฟล์ 'helper_functions.py' แล้วหรือไม่\n",
    "if os.path.exists(\"going_modular\") and os.path.exists(\"going_modular/helper_functions.py\"):\n",
    "    print(\"[INFO] Required files and folders already exist. Skipping download.\")\n",
    "else:\n",
    "    print(\"[INFO] Downloading module from GitHub by mrdbourke.\")\n",
    "    # Clone repository\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    \n",
    "    # Move 'going_modular' to the current directory\n",
    "    !move pytorch-deep-learning\\going_modular .\n",
    "    \n",
    "    # Move 'helper_functions.py' to the 'going_modular' folder\n",
    "    !move pytorch-deep-learning\\helper_functions.py going_modular\n",
    "    \n",
    "    # Remove the cloned repository\n",
    "    !rmdir /s /q pytorch-deep-learning\n",
    "    \n",
    "    # Remove 'going_modular/models' folder if it exists\n",
    "    !rmdir /s /q going_modular\\models\n",
    "    !rmdir /s /q pytorch-deep-learning\n",
    "    print(\"[INFO] Download and setup completed.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision \n",
    "import matplotlib.pyplot as plt \n",
    "import pathlib\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from going_modular.going_modular import data_setup,engine,utils\n",
    "from going_modular.helper_functions import download_data, set_seeds, plot_loss_curves\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict ,Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a model for resnet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_resnet50_model(num_classes:int=3,\n",
    "                          seed:int=42,\n",
    "                          dropout_rate: float = 0.3):  # เพิ่ม dropout_rate\n",
    "  # 1. Setup pretrained ResNet50 weights\n",
    "  weights = torchvision.models.ResNet50_Weights.DEFAULT  # Use the default weights\n",
    "  \n",
    "  # 2. Get ResNet50 transforms\n",
    "  transforms = weights.transforms()\n",
    "  \n",
    "  # 3. Setup pretrained model instance\n",
    "  model = torchvision.models.resnet50(weights=weights)  # Use the pretrained ResNet50\n",
    "  \n",
    "  # 4. Freeze the base layers in the model (this will stop all layers from training)\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "  \n",
    "  # 5. Change classifier head with random seed for reproducibility\n",
    "  torch.manual_seed(seed)\n",
    "  \n",
    "  # เพิ่ม Dropout และกำหนด output เป็น num_classes\n",
    "  model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=dropout_rate),  # เพิ่ม dropout\n",
    "    nn.Linear(in_features=model.fc.in_features, out_features=num_classes, bias=True)\n",
    "  )\n",
    "  \n",
    "  return model, transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call function create_resnet50_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet50_pets, resnet50_transforms = create_resnet50_model(num_classes=37,dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print ResNet50 model summary (uncomment for full output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ResNet (ResNet)                          [1, 3, 224, 224]     [1, 37]              --                   Partial\n",
       "├─Conv2d (conv1)                         [1, 3, 224, 224]     [1, 64, 112, 112]    (9,408)              False\n",
       "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]    [1, 64, 112, 112]    (128)                False\n",
       "├─ReLU (relu)                            [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --\n",
       "├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   --\n",
       "├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 256, 56, 56]     --                   False\n",
       "│    └─Bottleneck (0)                    [1, 64, 56, 56]      [1, 256, 56, 56]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      (4,096)              False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 64, 56, 56]      [1, 256, 56, 56]     (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56]     [1, 256, 56, 56]     (512)                False\n",
       "│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 256, 56, 56]     (16,896)             False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 56, 56]     [1, 256, 56, 56]     --                   --\n",
       "│    └─Bottleneck (1)                    [1, 256, 56, 56]     [1, 256, 56, 56]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 56, 56]     [1, 64, 56, 56]      (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 64, 56, 56]      [1, 256, 56, 56]     (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56]     [1, 256, 56, 56]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 56, 56]     [1, 256, 56, 56]     --                   --\n",
       "│    └─Bottleneck (2)                    [1, 256, 56, 56]     [1, 256, 56, 56]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 56, 56]     [1, 64, 56, 56]      (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 64, 56, 56]      [1, 256, 56, 56]     (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 256, 56, 56]     [1, 256, 56, 56]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 56, 56]     [1, 256, 56, 56]     --                   --\n",
       "├─Sequential (layer2)                    [1, 256, 56, 56]     [1, 512, 28, 28]     --                   False\n",
       "│    └─Bottleneck (0)                    [1, 256, 56, 56]     [1, 512, 28, 28]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 56, 56]     [1, 128, 56, 56]     (32,768)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 56, 56]     [1, 128, 56, 56]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 56, 56]     [1, 128, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 56, 56]     [1, 128, 28, 28]     (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]     [1, 512, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]     [1, 512, 28, 28]     (1,024)              False\n",
       "│    │    └─Sequential (downsample)      [1, 256, 56, 56]     [1, 512, 28, 28]     (132,096)            False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]     [1, 512, 28, 28]     --                   --\n",
       "│    └─Bottleneck (1)                    [1, 512, 28, 28]     [1, 512, 28, 28]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]     [1, 128, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]     [1, 512, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]     [1, 512, 28, 28]     (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]     [1, 512, 28, 28]     --                   --\n",
       "│    └─Bottleneck (2)                    [1, 512, 28, 28]     [1, 512, 28, 28]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]     [1, 128, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]     [1, 512, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]     [1, 512, 28, 28]     (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]     [1, 512, 28, 28]     --                   --\n",
       "│    └─Bottleneck (3)                    [1, 512, 28, 28]     [1, 512, 28, 28]     --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]     [1, 128, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 128, 28, 28]     [1, 512, 28, 28]     (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 512, 28, 28]     [1, 512, 28, 28]     (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 28, 28]     [1, 512, 28, 28]     --                   --\n",
       "├─Sequential (layer3)                    [1, 512, 28, 28]     [1, 1024, 14, 14]    --                   False\n",
       "│    └─Bottleneck (0)                    [1, 512, 28, 28]     [1, 1024, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 28, 28]     [1, 256, 28, 28]     (131,072)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 28, 28]     [1, 256, 28, 28]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 28, 28]     [1, 256, 28, 28]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 28, 28]     [1, 256, 14, 14]     (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]     [1, 1024, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]    [1, 1024, 14, 14]    (2,048)              False\n",
       "│    │    └─Sequential (downsample)      [1, 512, 28, 28]     [1, 1024, 14, 14]    (526,336)            False\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   --\n",
       "│    └─Bottleneck (1)                    [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]    [1, 256, 14, 14]     (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]     [1, 1024, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]    [1, 1024, 14, 14]    (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   --\n",
       "│    └─Bottleneck (2)                    [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]    [1, 256, 14, 14]     (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]     [1, 1024, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]    [1, 1024, 14, 14]    (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   --\n",
       "│    └─Bottleneck (3)                    [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]    [1, 256, 14, 14]     (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]     [1, 1024, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]    [1, 1024, 14, 14]    (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   --\n",
       "│    └─Bottleneck (4)                    [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]    [1, 256, 14, 14]     (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]     [1, 1024, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]    [1, 1024, 14, 14]    (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   --\n",
       "│    └─Bottleneck (5)                    [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]    [1, 256, 14, 14]     (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 256, 14, 14]     [1, 1024, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 1024, 14, 14]    [1, 1024, 14, 14]    (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [1, 1024, 14, 14]    [1, 1024, 14, 14]    --                   --\n",
       "├─Sequential (layer4)                    [1, 1024, 14, 14]    [1, 2048, 7, 7]      --                   False\n",
       "│    └─Bottleneck (0)                    [1, 1024, 14, 14]    [1, 2048, 7, 7]      --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 1024, 14, 14]    [1, 512, 14, 14]     (524,288)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 14, 14]     [1, 512, 14, 14]     (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 14, 14]     [1, 512, 14, 14]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 14, 14]     [1, 512, 7, 7]       (2,359,296)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]       [1, 2048, 7, 7]      (1,048,576)          False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7]      [1, 2048, 7, 7]      (4,096)              False\n",
       "│    │    └─Sequential (downsample)      [1, 1024, 14, 14]    [1, 2048, 7, 7]      (2,101,248)          False\n",
       "│    │    └─ReLU (relu)                  [1, 2048, 7, 7]      [1, 2048, 7, 7]      --                   --\n",
       "│    └─Bottleneck (1)                    [1, 2048, 7, 7]      [1, 2048, 7, 7]      --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 2048, 7, 7]      [1, 512, 7, 7]       (1,048,576)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]       [1, 2048, 7, 7]      (1,048,576)          False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7]      [1, 2048, 7, 7]      (4,096)              False\n",
       "│    │    └─ReLU (relu)                  [1, 2048, 7, 7]      [1, 2048, 7, 7]      --                   --\n",
       "│    └─Bottleneck (2)                    [1, 2048, 7, 7]      [1, 2048, 7, 7]      --                   False\n",
       "│    │    └─Conv2d (conv1)               [1, 2048, 7, 7]      [1, 512, 7, 7]       (1,048,576)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
       "│    │    └─Conv2d (conv3)               [1, 512, 7, 7]       [1, 2048, 7, 7]      (1,048,576)          False\n",
       "│    │    └─BatchNorm2d (bn3)            [1, 2048, 7, 7]      [1, 2048, 7, 7]      (4,096)              False\n",
       "│    │    └─ReLU (relu)                  [1, 2048, 7, 7]      [1, 2048, 7, 7]      --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [1, 2048, 7, 7]      [1, 2048, 1, 1]      --                   --\n",
       "├─Sequential (fc)                        [1, 2048]            [1, 37]              --                   True\n",
       "│    └─Dropout (0)                       [1, 2048]            [1, 2048]            --                   --\n",
       "│    └─Linear (1)                        [1, 2048]            [1, 37]              75,813               True\n",
       "========================================================================================================================\n",
       "Total params: 23,583,845\n",
       "Trainable params: 75,813\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (Units.GIGABYTES): 4.09\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 177.82\n",
       "Params size (MB): 94.34\n",
       "Estimated Total Size (MB): 272.76\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(resnet50_pets,\n",
    "        input_size=(1, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataLoaders for resnet50 feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('img/train'), WindowsPath('img/test'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pet_path = Path(\"./img\")\n",
    "train_dir = data_pet_path / \"train\"\n",
    "test_dir = data_pet_path / \"test\"\n",
    "train_dir,test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cpu core\n",
    "Count cpu for use on num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os_cpu_count = os.cpu_count()\n",
    "os_cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup resnet50 dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup resnet50 dataloaders\n",
    "from going_modular.going_modular import data_setup\n",
    "train_dataloader_resnet50_pet_pretrained, test_dataloader_resnet50_pet_pretrained, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                                                     test_dir=test_dir,\n",
    "                                                                                                     transform=resnet50_transforms,\n",
    "                                                                                                     batch_size=32,\n",
    "                                                                                                     num_workers=16) # Could increase if we had more samples, such as here: https://arxiv.org/abs/2205.01580 (there are other improvements there too...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking batch size each dataloder from \n",
    "train_dataloader_pet_pretrained and test_dataloader_pet_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149,\n",
       " 47,\n",
       " ['Abyssinian',\n",
       "  'Bengal',\n",
       "  'Birman',\n",
       "  'Bombay',\n",
       "  'British_Shorthair',\n",
       "  'Egyptian_Mau',\n",
       "  'Maine_Coon',\n",
       "  'Persian',\n",
       "  'Ragdoll',\n",
       "  'Russian_Blue'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader_resnet50_pet_pretrained),len(test_dataloader_resnet50_pet_pretrained),class_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training resnet50 Feature \n",
    "**`lr=1e-3 = 0.001`** is a suitable starting value, especially for medium to large models (e.g., ResNet or EfficientNet) and optimizers like Adam or AdamW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=resnet50_pets.parameters(),\n",
    "                             lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the classifier head of the pretrained resnet50 feature extractor model\n",
    "set_seeds()\n",
    "pretrained_resnet50_pets_results = engine.train(model=resnet50_pets,\n",
    "                                      train_dataloader=train_dataloader_resnet50_pet_pretrained,\n",
    "                                      test_dataloader=test_dataloader_resnet50_pet_pretrained,\n",
    "                                      optimizer=optimizer,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      epochs=5,\n",
    "                                      device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot loss curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(pretrained_resnet50_pets_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_model(model=resnet50_pets,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"pretrained_resnet50_pets.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model size in bytes and convert to megabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_resnet50_model_size = Path(\"models/pretrained_resnet50_pets.pth\").stat().st_size / (1024 * 1024)\n",
    "print(f\"Pretrained Resnet50 feature extractor model size: {round(pretrained_resnet50_model_size, 2)} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of parameters in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_pets_total_params = sum(torch.numel(param) for param in resnet50_pets.parameters())\n",
    "resnet50_pets_total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create a dictionary with Resnet50 Pet for keep records statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_pets_status = {\"test_loss\": pretrained_resnet50_pets_results[\"test_loss\"][-1],\n",
    "                  \"test_acc\": pretrained_resnet50_pets_results[\"test_acc\"][-1],\n",
    "                  \"number_of_parameters\": resnet50_pets_total_params,\n",
    "                  \"model_size (MB)\": pretrained_resnet50_model_size}\n",
    "\n",
    "resnet50_pets_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Visualize Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions with our trained models and timing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Making predictions with our trained models and timing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all test data img \n",
    "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
    "test_data_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to make across the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict resnet50_pets\n",
    "from going_modular.going_modular import predictions\n",
    "resnet50_pets_test_pred_dicts  = pred_and_store(model = resnet50_pets,\n",
    "                         target_paths = test_data_paths,\n",
    "                         transforms = resnet50_transforms,\n",
    "                         class_names = class_names,\n",
    "                         device = \"cpu\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
